# Data-Analysis-Portfolio-by-Rajveer-Seehra
Data Analysis Portfolio 


# [Particle Physics Research (MOLLER Group)](https://github.com/rjseehra/generatoranalysis)
A set of analysis python scripts created to run over large root files returned from particle generation simulations. The main functionality of these scripts is to provide standardized particle rate comparisons to provide insight on the optimization of a detector system being created for JeffersonLab in Virginia, USA. Utilizing python and its packages (namely NumPy, Pandas, matplotlib, and upRoot), as well as R and a keen understanding of root file structure, efficient analysis was obtained for varying parameters within the detector system. 

# [Webscraper using Selenium](https://github.com/rjseehra/webscrapingwithselenium)
A personal project of mine to simplify my weekly calendar. Using Selenium and NumPy, this scrapes a shift scheduling site for my weekly shifts to circumvent login and webpage navigation. Shift data is retrieved and formatted into an array iterated by day, date, and time. 

# [SQL for Data Science Coursera Capstone Project](https://github.com/rjseehra/SQL_for_Data_Science)
Utilizing a Yelp dataset filled with business data, I profiled and came up with detailed analysis and points of inference to help better understand the trends hidden in the dataset. This was a SQL focused project coupled with a creative and analytic problem solving approach. Upon completion of this Capstone project, I successfully attained certification in the SQL for Data Science course on Coursera. 

# [Camera Cleaning](https://github.com/rjseehra/CameraCleaning)
By reorganizing and cleaning up a datatset, I set up an aggregated form of the data that was then used for a Pivot Table within Excel. The further analysis done provides an easier and more convenient way to compare different Camera brands and their different characteristics, mainly those that would be considered during purchase. 

# [Cereal Data Cleaning](https://github.com/rjseehra/Cereal_Data_Cleaning)
Taking a chaotic dataset that has limited structure, I correctly profiled, organized, and cleaned the data to provide both easier readability and data structure. This was done through Excel and therefore through the usage of Excel tools. 
